\documentclass[DM,lsstdraft,toc]{lsstdoc}

% lsstdoc documentation: https://lsst-texmf.lsst.io/lsstdoc.html

% Package imports go here.
\usepackage{enumitem}

% Local commands go here.

\newcounter{usecase}
\newcommand{\usecase}[2]{
  \refstepcounter{usecase}
  \subsection{\emph{#1\theusecase}: #2}\label{use:#1\theusecase}
}

\newenvironment{flow}[1][Basic flow]
  {\subsubsection*{#1}\begin{enumerate}[label=\alph*.,itemsep=0pt]}
  {\end{enumerate}}

% To add a short-form title:
% \title[Short title]{Title}
\title{Offline Batch Production Service Use Cases}

% Optional subtitle
% \setDocSubtitle{A subtitle}

\author{Mikolaj Kowalik, Michelle Gower, and Rob Kooper}

\setDocRef{LDM-633}

\date{\today}

% Optional: name of the document's curator
% \setDocCurator{The Curator of this Document}

\setDocAbstract{%
  This document describes use cases for Offline Batch Production Service.
} 

% Change history defined here.
% Order: oldest first.
% Fields: VERSION, DATE, DESCRIPTION, OWNER NAME.
% See LPM-51 for version number policy.
\setDocChangeRecord{%
  \addtohist{1}{YYY-MM-DD}{Unreleased.}{Mikolaj Kowalik}
}


\begin{document}

% Create the title page.
% Table of contents is added automatically with the "toc" class option.
\maketitle

\section{Introduction}

This document describes use cases for the LSST Offline Batch Production
Service.  These use cases are driven by offline production processing, but may
also apply to other user needs, e.g. pipeline developers.

Offline Batch Production Service includes both the Campaign Management and
Workload/Workflow software products.  The service executes science payloads as
"campaigns" consisting of a defined pipeline, a defined configuration, and
defined inputs and outputs.  Many different payloads may be executed on many
different campaign cadences.  The service is able to handle massively
distributed computing allocating work across multiple enclaves, in particular
between NCSA and the Satellite Facility at CC-IN2P3, which will have capacity
for half of the DRP processing.

Many operations such as submissions, restarts, pauses, terminations,
monitoring, etc., apply to single pipelines or groups of pipelines.  To avoid
repetition, this use case document groups them together unless explicitly
specified otherwise.

\section{Definitions}

\begin{description}
  \item[Pipeline step definition]
    Data independent description of algorithmic worki (in Gen3 Middleware
    nomenclature it is called a PipelineTask)
  \item[Pipeline] 
    A sequence of individual pipeline step definitions, ordered according to
    their data dependencies, that performs particular data analysis and product
    generation (see LDM-151 for science definitions of pipelines).
  \item[Payload]
    A sequence of pipelines to achieve an LSST objective, e.g. a sequence of
    pipelines to be used for DRP (sometimes referred to as a ``production'').
  \item[Campaign]
    A payload with defined configuration and inputs to achieve a specific LSST
    objective, e.g., the DRP payload, specific configuration and specific set
    of inputs.
  \item[Pipeline step instances]
    A single instance of a pipeline step definition with specific inputs and
    outputs (in Gen3 Middleware, it is called a Quantum)
  \item[Job]
    A unit of execution submitted via platform's batch computing service (it
    may consist of one or more pipeline step instances)
  \item[Workflow]
    A collection of jobs ordered by data dependencies (in Gen3 Middleware, it
    is a result of applying an execution configuration to a QuantumGraph,
    grouping pipeline step instances into jobs)
\end{description}

\section{Actors}

\begin{description}
  \item[Operator (OP)]
    A person responsible for offline processing (e.g. DRP).

  \item[Campaign Manager (CM)]
    A system or person managing processing campaigns.

  \item[Worfklow Management System (WMS)]
    A system managing an execution of a pipeline.
\end{description}


\section{Pre-submit}

\usecase{BPS}{Override default configuration options}
The Operator wants to override a subset of configuration options for a
campaign/pipeline at any configuration level (i.e., global, site, campaign,
payload, pipeline step definition).  These overrides include but are not
limited to:
\begin{itemize}
  \item
    execution configuration of a pipeline step definition (e.g., expected
    amount of memory needed),
  \item
    science configuration of a pipeline step definition (e.g., update
    particular threshold),
  \item
    globally override certain configurations (e.g., whether to bring all output
    datasets home from job including intermediates),
  \item
    specify to process campaign/payload/pipeline step definitions on particular
    computational platform(s) or providing a list of specific machine(s) to
    avoid (e.g., run on cluster at CC-IN2P3 but avoid specific machines cc3000
    and cc4003).
  \item
    excluding certain data from a campaign.
\end{itemize}

\usecase{BPS}{Modify pipeline}
The Operator modifies sequence of pipeline step definitions. Modification may
include: 
\begin{itemize}
  \item
    deleting pipeline step definitions (e.g. only running half of a pipeline
    for debugging),
  \item
    adding new pipeline step definitions,
  \item
    reordering existing sequence of pipeline step definitions for science
    reasons.
\end{itemize}

\usecase{BPS}{Select specific software version(s)}
The Operator requests to run a campaign with specific versions of the LSST
packages (e.g. wants to use a particular LSST Stack release or specific
versions of individual packages).

\usecase{BPS}{Execute workflow in specific order}
The Operator specifies the order in which the workflow should be executed
including, but not limited to, breadth-first search and depth-first search.

\usecase{BPS}{Support dynamic workflows}
The workflow of certain pipelines may not be determinable at submit time, but
require discovering what outputs were actually created at runtime for certain
steps for determining number of instances of subsequent steps in the
workflow.  In this case, the Operator will need to indicate where in the
pipeline the dynamic generation is required.

\usecase{BPS}{Reduce number of compute jobs}
The Operator configures the BPS to group portions of the workflow into smaller
number of compute jobs to reduce the time overhead related to job startup
costs.

\usecase{BPS}{Halt or continue on failures}
The Operator configures the BPS whether to stop or continue workflow execution
based on failures of specific pipeline step instances.

\usecase{BPS}{Save intermediate datasets}
The Operator turns on/off the saving of intermediate datasets during submit
time (e.g. for debugging purposes).

\usecase{BPS}{Deal with unknown/defective data}
The Operator configures the BPS to stage out any files that are not expected
(i.e. are in a wrong place, have wrong name) or are missing some of required
metadata.

\usecase{BPS}{Prioritize campaigns/payloads}
The Operator assigns different processing priorities for campaigns/payloads at
time of submission. 

\section{Runtime}

\usecase{BPS}{Initiate a campaign}
The Operator specifies a campaign and submits it for processing.

\usecase{BPS}{Terminate a campaign/payload}
The Operator declares a running campaign/payload to be a failure. The
BPS should terminate its processing immediately.

\usecase{BPS}{Free resources used by a campaign/payload}
The Operator or CM wants to free resources used by campaigns/payloads to
initiate a campaign with higher priority or for maintenance. The BPS should
stop dispatching new workflows or compute jobs.  The Operator will also need to
unpause campaigns/payloads that have been put on hold.  This does not include
the ability to change configuration, etc. for the campaign/payload.

\usecase{BPS}{Dispatch workflows/jobs to specific computational platform(s)}
The BPS dispatches workflows/jobs to computational platforms specified by the
Operator during submission time. If not specified, the BPS dispatches to an
appropriate computational resource based on workflow/job requirements.

\usecase{BPS}{Alter priorities of pending campaign/payloads}
The Operator needs to alter priorities for pending campaigns/payloads.

\usecase{BPS}{Use Gen2 Middleware}
The Operator submits a scientific payload which requires Gen2 Middleware
(until it is completely deprecated).

\usecase{BPS}{Use Gen3 Middleware}
The Operator submits a scientific payload which requires Gen3 Middleware (e.g.
to chain a set of PipelineTasks in memory).

\usecase{BPS}{Support optional inputs}
Certain steps in a workflow can proceed even when not all declared inputs are
present. Based on submit time configuration the WMS will continue with processing for such steps providing their minimal requirements are satisfied.

\usecase{BPS}{Retry defective steps/jobs}
Based on the submit time configuration, the WMS automatically retries defective
steps/jobs providing certain criteria are met (e.g. type of failure).  The
preference is to retry the minimal amount of workflow necessary, but leaving
flexibility to work around implementation difficulties.

\usecase{BPS}{Interact with the Data Backbone}
For production payloads, the BPS retrieves the inputs from the Data Backbone
and store the results there.

\usecase{BPS}{Dispatch and manage campaigns/payloads at scale}
The WMS dispatches and manages campaign/payloads at the scale needed to meet
LSST objectives within the objectiveâ€™s time constraints.

\usecase{BPS}{Monitor available resources}
The Operator checks what is the state of available computational resources
(e.g. are there any unscheduled outages).

\usecase{BPS}{Monitor workflow execution}
The Operator or the CM tracks workflow execution, i.e., monitors in real time
metrics such as:
\begin{itemize}
  \item
    number of pending, running, finished, and failed jobs/pipeline step
    instances;
  \item
    amount of computer resources (e.g. CPUs, memory, disk space) in use vs
    idle;
  \item
    job runtime information (e.g. host name, memory, wall/CPU time, data input
    and output volume).
  \item
    what pipeline step instance or framework step is currently running (if possible seeing
    stdout/stderr from the step) for when pipelines seem to be taking too long.
\end{itemize}

\usecase{BPS}{Verify results integrity}
Based on submit time configuration, the BPS verifies that all the required
outputs were generated and staged out correctly for each successful workflow.

Note: Validation that the payload configuration and execution produced the
correct results is outside of the scope of this use case.

\usecase{BPS}{Notify about runtime events}
Based on submit time configuration, the BPS sends notifications about
campaign/payload level events (e.g.  its failure, completion, jobs taking
longer than some operator-specified threshold, etc.)


\section{Post run}

\usecase{BPS}{Restart a campaign/payload}
The Operator requests to restart processing a failed campaign/payload from the
point as close as possible to the failure (i.e. not from the very beginning).
Restarting a campaign/payload may include one or more of the following:
changing software stack to be used, changing science configuration, changing
execution configuration, etc.

\usecase{BPS}{Designate point of restart}
A workflow execution may not hard fail at the correct step and hard fail later
or may seemly complete the entire pipeline but produce bad science results. Â An
Operator may choose to either submit a new campaign/payload or restart payload
at a failure point the operator chooses.

\usecase{BPS}{Investigate output datasets}
The Operator uses similar procedures and tools to investigate both
successful and failed campaign/payloads.

\usecase{BPS}{View runtime metrics and provenance}
For each workflow step (including pipeline step instances, scheduling, data
transfer, data loading, workflow generation, etc.), the Operator views/queries
information such as:

\begin{itemize}
  \item
    machine where it was executed,
  \item
    when it was running and time it took for the process to complete,
  \item
    amount of memory it used during its execution,
  \item
    version of software used,
  \item
    job's environment,
  \item
    what input datasets were used (where applicable),
  \item
    what output datasets were produced (where applicable).
\end{itemize}

\usecase{BPS}{View data quality metrics}
For each campaign/payload, the Operator views any metrics measuring
data quality output by the pipeline.

\usecase{BPS}{Browse stdout/stderr/logs}
The Operator analyzes stderr/stdout/logs finished workflows/jobs,
i.e., needs to be able to quickly find the log of a specific pipeline step
instance, search logs for certain keywords/phrases.

\usecase{BPS}{Compare pipeline executions}
The Operator compares multiple payload executions with regard to data
products, quality control and runtime metrics (e.g. to evaluate the impact of a
software change).

\usecase{BPS}{Summarize a campaign}
The Operator views a summary of a campaign, e.g., a breakdown showing
times, resource usage for individual pipelines (if possible, indicating
pipelines deviating from a norm).

% Include all the relevant bib files.
% https://lsst-texmf.lsst.io/lsstdoc.html#bibliographies
%\bibliography{lsst,lsst-dm,refs_ads,refs,books}

\end{document}
# vim: ts=2 sw=2 et
