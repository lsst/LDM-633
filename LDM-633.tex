\documentclass[DM,lsstdraft,toc]{lsstdoc}

% lsstdoc documentation: https://lsst-texmf.lsst.io/lsstdoc.html

% Package imports go here.
\usepackage{enumitem}

% Local commands go here.

\newcounter{usecase}
\counterwithin*{usecase}{section}
\newcommand{\usecase}[2]{
  \refstepcounter{usecase}
  \subsection{\emph{#1\theusecase}: #2}\label{use:#1\theusecase}
}

\newenvironment{flow}[1][Basic flow]
  {\subsubsection*{#1}\begin{enumerate}[label=\alph*.,itemsep=0pt]}
  {\end{enumerate}}

% To add a short-form title:
% \title[Short title]{Title}
\title{Offline Batch Production Service Use Cases}

% Optional subtitle
% \setDocSubtitle{A subtitle}

\author{Mikolaj Kowalik, Michelle Gower, and Rob Kooper}

\setDocRef{LDM-633}

\date{\today}

% Optional: name of the document's curator
% \setDocCurator{The Curator of this Document}

\setDocAbstract{%
  This document describes use cases for Offline Batch Production Service.
} 

% Change history defined here.
% Order: oldest first.
% Fields: VERSION, DATE, DESCRIPTION, OWNER NAME.
% See LPM-51 for version number policy.
\setDocChangeRecord{%
  \addtohist{1}{YYY-MM-DD}{Unreleased.}{Mikolaj Kowalik}
}


\begin{document}

% Create the title page.
% Table of contents is added automatically with the "toc" class option.
\maketitle

\section{Introduction}

This document describes use cases for the LSST Offline Batch Production
Service (BPS).  These use cases are driven by offline production
processing, but may also apply to other user needs, e.g. pipeline
developers.

Offline Batch Production Service includes both the Campaign Management and
Workload/Workflow software products.  The service executes science payloads as
"campaigns" consisting of a defined sequence of pipelines, a defined
configuration, and defined inputs and outputs.  Many different payloads may be
executed on many different campaign cadences.  The service is able to handle
massively distributed computing allocating work across multiple enclaves, in
particular between NCSA and the Satellite Facility at CC-IN2P3, which will have
capacity for half of the DRP processing.  As the way science pipelines are
executed in the BPS differs significantly from the way it is done by most
science pipelines developers, the service needs to provide additional set of
features for offline production processing.

This service use case document does not cover portions of what would be
covered in complete Operations use cases, e.g., having change board
approval (or pre-approved rules) prior to changing a configuration.    

Many operations such as submissions, restarts, pauses, terminations,
monitoring, etc., apply to single pipelines or groups of pipelines.  To avoid
repetition, this use case document groups them together unless explicitly
specified otherwise.

\section{Definitions}

\begin{description}
  \item[Pipeline step definition]
    Data independent description of algorithmic work (in Gen3 Middleware
    nomenclature it is called a PipelineTask)
  \item[Pipeline] 
    A sequence of individual pipeline step definitions that performs particular
    data analysis and product generation (see LDM-151 for science definitions
    of pipelines).
  \item[Payload]
    A sequence of pipelines to achieve an LSST objective, e.g. a sequence of
    pipelines to be used for DRP (sometimes referred to as a ``production'').
  \item[Campaign]
    A payload with defined configuration and inputs to achieve a
    specific LSST objective, e.g., the DRP payload, specific
    configuration and specific set of inputs. A campaign describes
    \emph{what} work is required to achieve that objective.  Depending on
    its configuration, it corresponds to a set of workflows (see the
    definition below) which determine \emph{how} the required work will be
    done.
  \item[Subcampaign]
    A part of a campaign obtained via subsetting a payload and/or inputs.
  \item[Pipeline step instances]
    A single instance of a pipeline step definition with specific inputs and
    outputs (in Gen3 Middleware, it is called a Quantum)
  \item[Job]
    A unit of execution submitted via platform's batch computing
    service. It may consist of one or more pipeline step instances.
  \item[Workflow]
    A collection of jobs ordered by data dependencies represented as a direct,
    acyclic graph (in Gen3 Middleware, it is a result of applying an execution
    configuration to a QuantumGraph, grouping pipeline step instances into
    jobs).
\end{description}

\section{Actors}

\begin{description}
  \item[Operator (OP)]
    A person responsible for offline processing (e.g. DRP). 
  \item[Campaign Manager (CM)]
    A system or person managing processing campaigns.
  \item[Workflow Management System (WMS)]
    An infrastructure for the set-up, execution and monitoring of a defined
    workflow
\end{description}


\section{Pre-runtime}

\usecase{PRE}{Override default configuration options}
The Operator wants to override a subset of configuration options for a
campaign/pipeline at any configuration level (i.e., global, site, campaign,
payload, pipeline step definition).  These overrides include but are not
limited to:
\begin{itemize}
  \item
    execution configuration of a pipeline step definition (e.g., expected
    amount of memory needed),
  \item
    science configuration of a pipeline step definition (e.g., update
    particular threshold),
  \item
    globally override certain configurations (e.g., whether to bring all output
    datasets home from job including intermediates),
  \item
    specify to process campaign/payload/pipeline step definitions on particular
    computational platform(s) or providing a list of specific machine(s) to
    avoid (e.g., run on cluster at CC-IN2P3 but avoid specific machines cc3000
    and cc4003).
  \item
    excluding certain data from a campaign.
\end{itemize}
As it was mentioned earlier, which changes of configuration are pre-approved
and which require change board approval is beyond scope of this document.
Regardless of the LSST operation change protocol, the Operator needs an ability 
to make approved configuration changes.


\usecase{PRE}{Modify pipeline}
The Operator modifies sequence of pipeline step definitions. Modification may
include: 
\begin{itemize}
  \item
    deleting pipeline step definitions (e.g. only running half of a pipeline
    for debugging),
  \item
    adding new pipeline step definitions,
  \item
    reordering existing sequence of pipeline step definitions for science
    reasons.
\end{itemize}

\usecase{PRE}{Select specific software version(s)}
The Operator requests to run a campaign with specific versions of the
LSST packages (e.g. wants to use a particular release of LSST Scientific
Pipelines or specific versions of individual packages).

\usecase{PRE}{Execute workflow in specific order}
The Operator specifies the order in which the workflow should be executed
including, but not limited to, breadth-first search and depth-first search.

\usecase{PRE}{Support dynamic workflows}
The workflow of certain pipelines may not be determinable at submit
time, but require discovering what outputs were actually created at
runtime for certain steps for determining number of instances of
subsequent steps in the workflow.  In this case, the Operator need
to indicate where in the pipeline the dynamic generation is required.
The dynamic generation is related to data discovery only. It does not
include a support for conditional execution or rerunning jobs or parts
of the workflow based on some quality metrics.

\usecase{PRE}{Reduce number of compute jobs}
The Operator configures the BPS to group portions of the workflow into smaller
number of compute jobs to reduce the time overhead related to job startup
costs.

\usecase{PRE}{Halt or continue on failures}
The Operator configures the BPS whether to stop or continue workflow execution
based on failures of specific pipeline step instances.

\usecase{PRE}{Save intermediate datasets}
The Operator turns on/off the saving of intermediate datasets during submit
time (e.g. for debugging purposes).

\usecase{PRE}{Deal with unknown/defective data}
The Operator configures the BPS to stage out any files that are not expected
(i.e. not listed, are in a wrong place, have wrong name) or are missing some of
required metadata.

\usecase{PRE}{Prioritize (sub)campaigns}
The Operator assigns different processing priorities for (sub)campaigns at
time of submission. 

\usecase{PRE}{Initiate a campaign}
The Operator specifies a campaign and submits it for processing.


\section{Runtime}

\usecase{RUN}{Terminate a (sub)campaign}
The Operator declares a running (sub)campaign to be a failure. The BPS should
terminate its processing immediately.

\usecase{RUN}{Pause a (sub)campaign}
The Operator orders the BPS to stop dispatching new workflows/jobs
associated with a selected running (sub)campaign either to free
resources for a campaign with higher priority or due to site maintenance.

\usecase{RUN}{Alter compute resources}
The Operator assigns new compute resources to a (sub)campaign put on
hold and orders the BPS to start dispatching related workflows/jobs.
This does not include the ability to change other aspects of
configuration for the (sub)campaign.

\usecase{RUN}{Dispatch workflows/jobs to specific computational platform(s)}
During submission time, the Operator provides a list of available
compute sites.  The BPS dispatches workflows/jobs to specified
computational platforms based on workflow/job requirements.  This
includes Operator's ability to enforce execution of selected
workflows/jobs on a specific platform.

\usecase{RUN}{Alter priorities of (sub)campaigns}
The Operator needs to alter priorities of a (sub)campaign (it does not imply
providing a support for eviction of running jobs with lower priorities).

\usecase{RUN}{Use Gen3 Middleware}
The Operator submits a (sub)campaign which requires Gen3 Middleware (e.g.
to chain a set of PipelineTasks in memory).

\usecase{RUN}{Support optional inputs}
Certain steps in a workflow can proceed even when not all declared inputs are
present.  The Operator wants the BPS to continue with processing for such steps
providing (a) all predecessors completed their execution and (b) minimal
requirements are satisfied.

\usecase{RUN}{Retry defective steps/jobs}
Based on the submit time configuration, the WMS automatically retries defective
steps/jobs providing certain criteria are met (e.g. type of failure).  The
preference is to retry the minimal amount of workflow necessary, but leaving
flexibility to work around implementation difficulties.

\usecase{RUN}{Interact with the Data Backbone}
For production payloads, the BPS retrieves the inputs from the Data Backbone
and store the results there.

\usecase{RUN}{Monitor available resources}
The Operator needs to be able to monitor the status of the BPS service as well
as any of its underpinning components (including any suspicions by BPS that a
node is not fit for use).

\usecase{RUN}{Monitor workflow execution}
The Operator or the CM tracks workflow execution, i.e., monitors in real time
metrics such as:
\begin{itemize}
  \item
    number of pending, running, finished, and failed jobs/pipeline step
    instances;
  \item
    amount of computer resources (e.g. CPUs, memory, disk space) in use;
  \item
    job runtime information (e.g. host name, memory, wall/CPU time, data input
    and output volume).
  \item
    what pipeline step instance or framework step is currently running (if
    possible seeing stdout/stderr from the step) for when pipelines seem to be
    taking too long.
\end{itemize}

\usecase{RUN}{Verify results integrity}
Based on submit time configuration, the BPS verifies that all the required
outputs were generated and staged out correctly for each successful workflow.

Note: Validation that the payload configuration and execution produced the
correct results is outside of the scope of this use case.

\usecase{RUN}{Notify about runtime events}
Based on submit time configuration, the BPS sends notifications about
campaign/payload level events (e.g.  its failure, completion, jobs taking
longer than some operator-specified threshold, etc.)


\section{Post-runtime}

\usecase{POST}{Restart a campaign/payload}
The Operator requests to restart processing a failed campaign/payload from the
point as close as possible to the failure (i.e. not from the very beginning).
Restarting a campaign/payload may include one or more of the following:
changing software stack to be used, changing science configuration, changing
execution configuration, etc.

\usecase{POST}{Designate point of restart}
A workflow execution may not hard fail at the correct step and hard fail later
or may seemly complete the entire pipeline but produce bad science results.  An
Operator may choose to either submit a new campaign/payload or restart payload
at a failure point the operator chooses.

\usecase{POST}{Investigate output datasets}
The Operator uses similar procedures and tools to investigate both
successful and failed campaign/payloads.

\usecase{POST}{View runtime metrics and provenance}
For each workflow step (including pipeline step instances, scheduling, data
transfer, data loading, workflow generation, etc.), the Operator views/queries
information such as:

\begin{itemize}
  \item
    machine where it was executed,
  \item
    when it was running and time it took for the process to complete,
  \item
    amount of memory it used during its execution,
  \item
    version of software used,
  \item
    job's environment,
  \item
    what input datasets were used (where applicable),
  \item
    what output datasets were produced (where applicable).
\end{itemize}

\usecase{POST}{Browse stdout/stderr/logs}
The Operator analyzes stderr/stdout/logs finished workflows/jobs,
i.e., needs to be able to quickly find the log of a specific pipeline step
instance, search logs for certain keywords/phrases.

\usecase{POST}{Compare pipeline executions}
The Operator compares multiple payload executions with regard to data
products and runtime metrics (e.g. to evaluate the impact of a
software change).

\usecase{POST}{Summarize a campaign}
The Operator views a summary of a campaign, e.g., a breakdown showing
times, resource usage for individual pipelines (if possible, indicating
pipelines deviating from a norm).

% Include all the relevant bib files.
% https://lsst-texmf.lsst.io/lsstdoc.html#bibliographies
%\bibliography{lsst,lsst-dm,refs_ads,refs,books}

\end{document}
# vim: ts=2 sw=2 et
